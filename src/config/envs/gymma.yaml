env: "gymma"

env_args:
  seed: 0
  key: null
  time_limit: 25
  pretrained_wrapper: null
  common_reward: True  # Run experiment with common reward setup
  reward_scalarisation: "sum"
  #N : 6
  #max_cycles : 500 
  #x_size : 16 
  #y_size : 16 
  #shared_reward : True 
  #n_evaders : 30
  #n_pursuers: 8
  #obs_range : 7
  #n_catch : 2 
  #freeze_evaders : False
  #tag_reward : 0.01
  #catch_reward : 5.0
  #urgency_reward : -0.1 
  #surround : True 
  #constraint_window : 1.0

test_greedy: True
test_nepisode: 100
test_interval: 50000
log_interval: 50000
runner_log_interval: 10000
learner_log_interval: 10000
t_max: 2059999999999999999999999999999999999999999999999990000

